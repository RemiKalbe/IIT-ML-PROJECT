{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Graph, ImpactCalculator and GNNAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.graph.graph.graph import Graph\n",
    "from lib.gnnanalyzer.gnnanalyzer.localgnnanalyzer import LocalGNNAnalyzer\n",
    "from lib.gnnanalyzer.gnnanalyzer.localimpactcalculator import (\n",
    "    LocalImpactCalculator,\n",
    "    LocalImpactCalculationMethod,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_IDX = 0  # Index for the identifier column in nodes\n",
    "NODE_FEATURE_START_IDX = 1  # Start index for node features columns\n",
    "NODE_FEATURE_END_IDX = 1433  # End index for node features columns\n",
    "CLASS_IDX = 1434  # Index for the class column in nodes\n",
    "SOURCE_IDX = 0  # Index for the source column in edges\n",
    "TARGET_IDX = 1  # Index for the target column in edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "g.import_edges_from_edge_list(\n",
    "    data=\"./datasets/cora/cora.cites\",\n",
    "    source_target_col=(SOURCE_IDX, TARGET_IDX),\n",
    "    override_data_file_extension=\".txt\",\n",
    "    delimiter=\"\t\",\n",
    ")\n",
    "g.import_nodes_from_node_list(\n",
    "    data=\"./datasets/cora/cora.content\",\n",
    "    node_identifier_col=NODE_IDX,\n",
    "    features_cols=[i for i in range(NODE_FEATURE_START_IDX, NODE_FEATURE_END_IDX)],\n",
    "    class_col=CLASS_IDX,\n",
    "    override_data_file_extension=\".txt\",\n",
    "    delimiter=\"\t\",\n",
    ")\n",
    "\n",
    "# To please PyLance\n",
    "assert g.nodes is not None\n",
    "assert g.edges is not None\n",
    "assert g.nodes.columns is not None\n",
    "assert g.edges.columns is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact = LocalImpactCalculator(method=LocalImpactCalculationMethod.ABSOLUTE_DIFFERENCE)\n",
    "analyzer = LocalGNNAnalyzer(graph=g, local_impact_calculator=impact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial testings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of a basic model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.graph.graph.graph import ExportFileFormat\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a very basic GNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GNN model\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the device to be used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_str = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available() and torch.backends.mps.is_built()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Graph Class allows us to get back the dataset in a multitude of formats; here we are getting a Polars DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2_708, 1_435)\n",
      "┌─────────┬───────────┬───────────┬───────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
      "│ Node    ┆ Feature 0 ┆ Feature 1 ┆ Feature 2 ┆ … ┆ Feature    ┆ Feature   ┆ column_14 ┆ Class     │\n",
      "│ ---     ┆ ---       ┆ ---       ┆ ---       ┆   ┆ 1430       ┆ 1431      ┆ 34        ┆ ---       │\n",
      "│ i64     ┆ i64       ┆ i64       ┆ i64       ┆   ┆ ---        ┆ ---       ┆ ---       ┆ str       │\n",
      "│         ┆           ┆           ┆           ┆   ┆ i64        ┆ i64       ┆ i64       ┆           │\n",
      "╞═════════╪═══════════╪═══════════╪═══════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ 31336   ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Neural_Ne │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ tworks    │\n",
      "│ 1061127 ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Rule_Lear │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ ning      │\n",
      "│ 1106406 ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Reinforce │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ ment_Lear │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ ning      │\n",
      "│ 13195   ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Reinforce │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ ment_Lear │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ ning      │\n",
      "│ …       ┆ …         ┆ …         ┆ …         ┆ … ┆ …          ┆ …         ┆ …         ┆ …         │\n",
      "│ 1128977 ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Genetic_A │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ lgorithms │\n",
      "│ 1128978 ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Genetic_A │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ lgorithms │\n",
      "│ 117328  ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Case_Base │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ d         │\n",
      "│ 24043   ┆ 0         ┆ 0         ┆ 0         ┆ … ┆ 0          ┆ 0         ┆ 0         ┆ Neural_Ne │\n",
      "│         ┆           ┆           ┆           ┆   ┆            ┆           ┆           ┆ tworks    │\n",
      "└─────────┴───────────┴───────────┴───────────┴───┴────────────┴───────────┴───────────┴───────────┘\n",
      "shape: (5_429, 2)\n",
      "┌────────┬─────────┐\n",
      "│ Source ┆ Target  │\n",
      "│ ---    ┆ ---     │\n",
      "│ i64    ┆ i64     │\n",
      "╞════════╪═════════╡\n",
      "│ 35     ┆ 1033    │\n",
      "│ 35     ┆ 103482  │\n",
      "│ 35     ┆ 103515  │\n",
      "│ 35     ┆ 1050679 │\n",
      "│ …      ┆ …       │\n",
      "│ 853116 ┆ 853155  │\n",
      "│ 853118 ┆ 1140289 │\n",
      "│ 853155 ┆ 853118  │\n",
      "│ 954315 ┆ 1155073 │\n",
      "└────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# Let's see how is our datasets once exported\n",
    "\n",
    "nodes_df = g.export_nodes_as_node_list(ExportFileFormat.POLARS_DF)\n",
    "edges_df = g.export_edges_as_edge_list(ExportFileFormat.POLARS_DF)\n",
    "\n",
    "assert isinstance(nodes_df, pl.DataFrame)\n",
    "assert isinstance(edges_df, pl.DataFrame)\n",
    "\n",
    "print(nodes_df)\n",
    "print(edges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to map the name of the columns in the dataframe to the indices we defined ealier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx to column name\n",
    "nodes_idx_to_col_name = {idx: col_name for idx, col_name in enumerate(nodes_df.columns)}  # type: ignore\n",
    "\n",
    "edges_idx_to_col_name = {idx: col_name for idx, col_name in enumerate(edges_df.columns)}  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function that converts the Graph Class to a PyTorch Geometric Data object, as this will repeatedly be used in the analysis process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_torch_geometric_data(\n",
    "    graph: Graph,\n",
    "    class_idx: int,\n",
    "    node_col_idx: int,\n",
    "    node_feature_start_idx: int,\n",
    "    node_feature_end_idx: int,\n",
    "    source_idx: int,\n",
    "    target_idx: int,\n",
    ") -> Data:\n",
    "    # Export the nodes and edges to the desired format\n",
    "    nodes_df = graph.export_nodes_as_node_list(ExportFileFormat.POLARS_DF)\n",
    "    edges_df = graph.export_edges_as_edge_list(ExportFileFormat.POLARS_DF)\n",
    "\n",
    "    assert isinstance(nodes_df, pl.DataFrame)\n",
    "    assert isinstance(edges_df, pl.DataFrame)\n",
    "\n",
    "    # From nodes idx to column name\n",
    "    nodes_col_node_name = nodes_idx_to_col_name[node_col_idx]\n",
    "    nodes_col_class_name = nodes_idx_to_col_name[class_idx]\n",
    "    node_col_features_name = [\n",
    "        nodes_idx_to_col_name[i]\n",
    "        for i in range(node_feature_start_idx, node_feature_end_idx)\n",
    "    ]\n",
    "\n",
    "    # From edges idx to column name\n",
    "    edges_col_source_name = edges_idx_to_col_name[source_idx]\n",
    "    edges_col_target_name = edges_idx_to_col_name[target_idx]\n",
    "\n",
    "    # Convert categorical class labels to numeric\n",
    "    class_labels = nodes_df.select(nodes_col_class_name).to_numpy()\n",
    "    encoder = LabelEncoder()\n",
    "    Y = encoder.fit_transform(class_labels)\n",
    "\n",
    "    # Process the nodes DataFrame\n",
    "    x = torch.tensor(\n",
    "        nodes_df.select(node_col_features_name).to_numpy(),\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    y = torch.tensor(Y, dtype=torch.long)\n",
    "\n",
    "    # Process the edges DataFrame\n",
    "    edge_index = (\n",
    "        torch.tensor(\n",
    "            edges_df.select([edges_col_source_name, edges_col_target_name]).to_numpy(),\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "        .t()\n",
    "        .contiguous()\n",
    "    )\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb Cell 20\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m output \u001b[39m=\u001b[39m model(torch_geo_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     output[torch_geo_data\u001b[39m.\u001b[39;49mtrain_mask], torch_geo_data\u001b[39m.\u001b[39my[torch_geo_data\u001b[39m.\u001b[39mtrain_mask]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/remikalbe/Git/github.com/IIT-ML-PROJECT/experimentations.ipynb#X21sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Git/github.com/IIT-ML-PROJECT/.venv/lib/python3.10/site-packages/torch_geometric/data/data.py:482\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    477\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 482\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m~/Git/github.com/IIT-ML-PROJECT/.venv/lib/python3.10/site-packages/torch_geometric/data/storage.py:87\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "# Convert the graph to a PyTorch Geometric Data object\n",
    "torch_geo_data = create_torch_geometric_data(\n",
    "    graph=g,\n",
    "    class_idx=CLASS_IDX,\n",
    "    node_col_idx=NODE_IDX,\n",
    "    node_feature_start_idx=NODE_FEATURE_START_IDX,\n",
    "    node_feature_end_idx=NODE_FEATURE_END_IDX,\n",
    "    source_idx=SOURCE_IDX,\n",
    "    target_idx=TARGET_IDX,\n",
    ")\n",
    "\n",
    "# Define some parameters for the GNN model\n",
    "input_dim = torch_geo_data.num_node_features\n",
    "hidden_dim = 64  # Example hidden dimension size\n",
    "output_dim = torch_geo_data.y.max().item() + 1  # Number of classes\n",
    "\n",
    "model = GNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(\n",
    "    device=device\n",
    ")\n",
    "torch_geo_data = torch_geo_data.to(device=device_str)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Criterion assumes model returns raw logits\n",
    "\n",
    "# Train the GNN model\n",
    "model.train()\n",
    "for epoch in range(200):  # A default number of epochs for the example\n",
    "    optimizer.zero_grad()\n",
    "    output = model(torch_geo_data)\n",
    "    loss = criterion(\n",
    "        output[torch_geo_data.train_mask], torch_geo_data.y[torch_geo_data.train_mask]\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Print the loss every 10 epochs or the last epoch\n",
    "    if epoch % 10 == 0 or epoch == 199:\n",
    "        print(f\"Epoch {epoch}: Loss {loss.item()}\")\n",
    "\n",
    "# Get prediction for a specific node (example node index 0)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(torch_geo_data)\n",
    "    # Use softmax to convert logits to probabilities\n",
    "    probs = F.softmax(output, dim=1)\n",
    "    predicted_class = (\n",
    "        probs[0].argmax().item()\n",
    "    )  # Get the predicted class for node at index 0\n",
    "\n",
    "print(f\"Predicted class for the node at index 0: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Integrate the trained model with the LocalGNNAnalyzer\n",
    "def predict_fn(node_features, edge_index):\n",
    "    # Prepare a tensor for node_features and edge_index based on GNN requirements\n",
    "    # Example: For PyG, use the following, adapted for the complete graph.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "    return out\n",
    "\n",
    "\n",
    "# Assuming we run the ablation step for node 5 (as an example)\n",
    "analyzer.prepare_ablation_plan(starting_node=\"5\", max_depth=3)\n",
    "while analyzer.has_next_step():\n",
    "    current_prediction = predict_fn(data.x, data.edge_index)\n",
    "    analyzer.execute_ablation_step(current_prediction)\n",
    "\n",
    "# Get the interpretation of the GNN's predictions\n",
    "interpretation = analyzer.get_interpretation()\n",
    "print(interpretation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
